{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "This model will be trained on the images classified as 'Male' by the Trousers_and_Jeans_Gender_Split model, and then further classify these images into the different types of trousers and jeans.\n",
    "\n",
    "The targets for the dataset are 'Trousers' and 'Jeans', and this makes this task a binary classification problem.  \n",
    "However, because of the hierarchical order of the models, these targets are really 'Male Trousers' and 'Male Jeans'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import environ # To get the file path of the datasets location from Windows environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets from the path stored in the operating system's environment variable\n",
    "dataset_path = environ.get('CNN_Practical_Dataset_Path')\n",
    "\n",
    "data_train = np.load(dataset_path + \"/Trousers & Jeans - Male - Train.npz\")\n",
    "data_validation = np.load(dataset_path + \"/Trousers & Jeans - Male - Validation.npz\")\n",
    "data_test = np.load(dataset_path + \"/Trousers & Jeans - Male - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_validation['images']\n",
    "labels_val = data_validation['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values of all images\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filters_number', hp.Discrete([64,96]))\n",
    "HP_DENSE_SIZE = hp.HParam('dense_size', hp.Discrete([256,512]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs_Practical/Model Trousers_and_Jeans_Type_Male/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE, HP_FILTER_NUM, HP_DENSE_SIZE],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it\n",
    "\n",
    "Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE], activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_DENSE_SIZE], activation='relu'),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs_Practical\\\\Model Trousers_and_Jeans_Type_Male\\\\fit\\\\\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        \n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Trousers', 'Jeans'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the results\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size': 5, 'filters_number': 64, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "32/32 - 35s - loss: 7.4457 - accuracy: 0.4995 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "32/32 - 33s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 3/20\n",
      "32/32 - 52s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 7.6661 - accuracy: 0.4720\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-1\\assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size': 5, 'filters_number': 64, 'dense_size': 512}\n",
      "Epoch 1/20\n",
      "32/32 - 38s - loss: 7.4456 - accuracy: 0.4960 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "32/32 - 37s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 3/20\n",
      "32/32 - 40s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 7.6661 - accuracy: 0.4720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-2\\assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size': 5, 'filters_number': 96, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "32/32 - 61s - loss: 7.4459 - accuracy: 0.4960 - val_loss: 7.6661 - val_accuracy: 0.5280\n",
      "Epoch 2/20\n",
      "32/32 - 63s - loss: 7.6687 - accuracy: 0.4980 - val_loss: 7.6661 - val_accuracy: 0.5280\n",
      "Epoch 3/20\n",
      "32/32 - 62s - loss: 7.6687 - accuracy: 0.4980 - val_loss: 7.6661 - val_accuracy: 0.5280\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 7.6661 - accuracy: 0.5280\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-3\\assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size': 5, 'filters_number': 96, 'dense_size': 512}\n",
      "Epoch 1/20\n",
      "32/32 - 66s - loss: 7.4458 - accuracy: 0.5025 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "32/32 - 66s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 3/20\n",
      "32/32 - 65s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 7.6661 - accuracy: 0.4720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-4\\assets\n",
      "--- Starting trial: run-5\n",
      "{'filter_size': 7, 'filters_number': 64, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "32/32 - 56s - loss: 1.1165 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5280\n",
      "Epoch 2/20\n",
      "32/32 - 76s - loss: 0.6931 - accuracy: 0.5210 - val_loss: 0.6931 - val_accuracy: 0.4720\n",
      "Epoch 3/20\n",
      "32/32 - 58s - loss: 0.6931 - accuracy: 0.4815 - val_loss: 0.6931 - val_accuracy: 0.5280\n",
      "Epoch 4/20\n",
      "32/32 - 57s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.4720\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 0.6931 - accuracy: 0.4720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-5\\assets\n",
      "--- Starting trial: run-6\n",
      "{'filter_size': 7, 'filters_number': 64, 'dense_size': 512}\n",
      "Epoch 1/20\n",
      "32/32 - 59s - loss: 7.4460 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "32/32 - 60s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 3/20\n",
      "32/32 - 58s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 7.6661 - accuracy: 0.4720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-6\\assets\n",
      "--- Starting trial: run-7\n",
      "{'filter_size': 7, 'filters_number': 96, 'dense_size': 256}\n",
      "Epoch 1/20\n",
      "32/32 - 104s - loss: 0.8308 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "32/32 - 100s - loss: 0.6931 - accuracy: 0.4910 - val_loss: 0.6931 - val_accuracy: 0.5280\n",
      "Epoch 3/20\n",
      "32/32 - 102s - loss: 0.6931 - accuracy: 0.5160 - val_loss: 0.6931 - val_accuracy: 0.4720\n",
      "8/8 [==============================] - 5s 674ms/step - loss: 0.6931 - accuracy: 0.4720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-7\\assets\n",
      "--- Starting trial: run-8\n",
      "{'filter_size': 7, 'filters_number': 96, 'dense_size': 512}\n",
      "Epoch 1/20\n",
      "32/32 - 116s - loss: 7.4458 - accuracy: 0.4990 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 2/20\n",
      "32/32 - 114s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "Epoch 3/20\n",
      "32/32 - 131s - loss: 7.6687 - accuracy: 0.5020 - val_loss: 7.6661 - val_accuracy: 0.4720\n",
      "8/8 [==============================] - 3s 368ms/step - loss: 7.6661 - accuracy: 0.4720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-8\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "        for dense_size in HP_DENSE_SIZE.domain.values:\n",
    "\n",
    "            hparams = {\n",
    "                HP_FILTER_SIZE: filter_size,\n",
    "                HP_FILTER_NUM: filter_num,\n",
    "                HP_DENSE_SIZE: dense_size\n",
    "            }\n",
    "\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('Logs_Practical/Model Trousers_and_Jeans_Type_Male/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models\\Model Trousers_and_Jeans_Type_Male\\Run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 126ms/step - loss: 7.6696 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 7.6696. Test accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12612), started 2:55:33 ago. (Use '!kill 12612' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b4b84d6620e42730\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b4b84d6620e42730\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Trousers_and_Jeans_Type_Male/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 16480."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Trousers_and_Jeans_Type_Male/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

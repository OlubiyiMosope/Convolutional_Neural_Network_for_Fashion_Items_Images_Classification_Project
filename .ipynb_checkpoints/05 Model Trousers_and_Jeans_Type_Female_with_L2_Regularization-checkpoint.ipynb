{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "This model will be trained on the images classified as 'Female' by the Trousers_and_Jeans_Gender_Split model, and then further classify these images into the different types of trousers and jeans.\n",
    "\n",
    "The targets for the dataset are 'Trousers' and 'Jeans', and this makes this task a binary classification problem.  \n",
    "However, because of the hierarchical order of the models, these targets are really 'Female Trousers' and 'Female Jeans'.\n",
    "\n",
    "###### Regularization\n",
    "This model will employ the L2 regularization technique to try improve the model's performance.\n",
    "\n",
    "This refers to the method of trying to modify the loss function with an  additional factor that is the sum of the model's weights squared.  \n",
    "\n",
    "$L^2 Regularization: L = L_0 + \\lambda\\Sigma w_i^2$  \n",
    "\n",
    "The objective is to scale down all non-essential weights as close to ero as possible while leaving the weights essential to the model relatively unchanged, thus simplifying the model and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import environ # To get the file path of the datasets location from Windows environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets from the path stored in the operating system's environment variable\n",
    "dataset_path = environ.get('CNN_Practical_Dataset_Path')\n",
    "\n",
    "data_train = np.load(dataset_path + \"/Trousers & Jeans - Female - Train.npz\")\n",
    "data_validation = np.load(dataset_path + \"/Trousers & Jeans - Female - Validation.npz\")\n",
    "data_test = np.load(dataset_path + \"/Trousers & Jeans - Female - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_validation['images']\n",
    "labels_val = data_validation['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values of all images\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2002, 120, 90, 3)\n",
      "(250, 120, 90, 3)\n",
      "(250, 120, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape)\n",
    "print(images_val.shape)\n",
    "print(images_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2002,)\n",
      "(250,)\n",
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train.shape)\n",
    "print(labels_val.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "FILTER_SIZE = 5\n",
    "FILTER_NUM = 64\n",
    "DENSE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_LAMBDA_REG = hp.HParam('lambda', hp.Discrete([0.0, 5e-05, 0.0005, 0.005, 0.05, 0.1]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs_Practical/Model Trousers_and_Jeans_Type_Female/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_LAMBDA_REG],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(FILTER_NUM, FILTER_SIZE, activation='relu', input_shape=(120,90,3), kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(FILTER_NUM, FILTER_SIZE, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(DENSE_SIZE, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_LAMBDA_REG])),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy',  tf.keras.losses.BinaryCrossentropy(from_logits=False, name='binary_crossentropy')])\n",
    "    \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs_Practical\\\\Model Trousers_and_Jeans_Type_Female\\\\fit\\\\\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        \n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Trousers', 'Jeans'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_binary_crossentropy',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy, _ = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models\\Model Trousers_and_Jeans_Type_Female\\Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'lambda': 0.0}\n",
      "Epoch 1/20\n",
      "32/32 - 37s - loss: 1.3328 - accuracy: 0.5060 - binary_crossentropy: 1.3184 - val_loss: 0.6931 - val_accuracy: 0.5160 - val_binary_crossentropy: 0.6931\n",
      "Epoch 2/20\n",
      "32/32 - 37s - loss: 0.6931 - accuracy: 0.4925 - binary_crossentropy: 0.6931 - val_loss: 0.6931 - val_accuracy: 0.5160 - val_binary_crossentropy: 0.6931\n",
      "Epoch 3/20\n",
      "32/32 - 37s - loss: 0.6931 - accuracy: 0.4960 - binary_crossentropy: 0.6931 - val_loss: 0.6931 - val_accuracy: 0.5120 - val_binary_crossentropy: 0.6931\n",
      "Epoch 4/20\n",
      "32/32 - 37s - loss: 0.6931 - accuracy: 0.4855 - binary_crossentropy: 0.6931 - val_loss: 0.6931 - val_accuracy: 0.5080 - val_binary_crossentropy: 0.6931\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.6931 - accuracy: 0.5160 - binary_crossentropy: 0.6931\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Female\\Run-1\\assets\n",
      "--- Starting trial: run-2\n",
      "{'lambda': 5e-05}\n",
      "Epoch 1/20\n",
      "32/32 - 38s - loss: 1.0462 - accuracy: 0.5130 - binary_crossentropy: 1.0022 - val_loss: 0.7210 - val_accuracy: 0.5160 - val_binary_crossentropy: 0.6931\n",
      "Epoch 2/20\n",
      "32/32 - 38s - loss: 0.7181 - accuracy: 0.5010 - binary_crossentropy: 0.6931 - val_loss: 0.7153 - val_accuracy: 0.4880 - val_binary_crossentropy: 0.6931\n",
      "Epoch 3/20\n",
      "32/32 - 38s - loss: 0.7136 - accuracy: 0.4805 - binary_crossentropy: 0.6931 - val_loss: 0.7120 - val_accuracy: 0.4960 - val_binary_crossentropy: 0.6931\n",
      "Epoch 4/20\n",
      "32/32 - 38s - loss: 0.7109 - accuracy: 0.4865 - binary_crossentropy: 0.6931 - val_loss: 0.7098 - val_accuracy: 0.5120 - val_binary_crossentropy: 0.6931\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.7153 - accuracy: 0.4880 - binary_crossentropy: 0.6931\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Female\\Run-2\\assets\n",
      "--- Starting trial: run-3\n",
      "{'lambda': 0.0005}\n",
      "Epoch 1/20\n",
      "32/32 - 46s - loss: 7.6995 - accuracy: 0.5020 - binary_crossentropy: 7.4510 - val_loss: 7.8245 - val_accuracy: 0.4840 - val_binary_crossentropy: 7.6671\n",
      "Epoch 2/20\n",
      "32/32 - 49s - loss: 7.7889 - accuracy: 0.5030 - binary_crossentropy: 7.6691 - val_loss: 7.7556 - val_accuracy: 0.4840 - val_binary_crossentropy: 7.6671\n",
      "Epoch 3/20\n",
      "32/32 - 48s - loss: 7.7391 - accuracy: 0.5030 - binary_crossentropy: 7.6690 - val_loss: 7.7209 - val_accuracy: 0.4840 - val_binary_crossentropy: 7.6671\n",
      "8/8 [==============================] - 1s 183ms/step - loss: 7.8245 - accuracy: 0.4840 - binary_crossentropy: 7.6668\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Female\\Run-3\\assets\n",
      "--- Starting trial: run-4\n",
      "{'lambda': 0.005}\n",
      "Epoch 1/20\n",
      "32/32 - 49s - loss: 2.2984 - accuracy: 0.4840 - binary_crossentropy: 1.0019 - val_loss: 1.0903 - val_accuracy: 0.4840 - val_binary_crossentropy: 0.6931\n",
      "Epoch 2/20\n",
      "32/32 - 48s - loss: 0.9630 - accuracy: 0.5090 - binary_crossentropy: 0.6931 - val_loss: 0.8746 - val_accuracy: 0.5040 - val_binary_crossentropy: 0.6931\n",
      "Epoch 3/20\n",
      "32/32 - 49s - loss: 0.8364 - accuracy: 0.4760 - binary_crossentropy: 0.6931 - val_loss: 0.8048 - val_accuracy: 0.4600 - val_binary_crossentropy: 0.6931\n",
      "Epoch 4/20\n",
      "32/32 - 48s - loss: 0.7876 - accuracy: 0.4396 - binary_crossentropy: 0.6931 - val_loss: 0.7724 - val_accuracy: 0.4440 - val_binary_crossentropy: 0.6931\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 0.8746 - accuracy: 0.5040 - binary_crossentropy: 0.6931\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Female\\Run-4\\assets\n",
      "--- Starting trial: run-5\n",
      "{'lambda': 0.05}\n",
      "Epoch 1/20\n",
      "32/32 - 49s - loss: 11.5373 - accuracy: 0.5260 - binary_crossentropy: 0.8116 - val_loss: 2.3321 - val_accuracy: 0.5520 - val_binary_crossentropy: 0.6931\n",
      "Epoch 2/20\n",
      "32/32 - 49s - loss: 1.5601 - accuracy: 0.4945 - binary_crossentropy: 0.6931 - val_loss: 1.1636 - val_accuracy: 0.4840 - val_binary_crossentropy: 0.6931\n",
      "Epoch 3/20\n",
      "32/32 - 49s - loss: 1.0614 - accuracy: 0.4850 - binary_crossentropy: 0.6931 - val_loss: 0.9839 - val_accuracy: 0.5160 - val_binary_crossentropy: 0.6931\n",
      "Epoch 4/20\n",
      "32/32 - 49s - loss: 0.9412 - accuracy: 0.4980 - binary_crossentropy: 0.6931 - val_loss: 0.9007 - val_accuracy: 0.5160 - val_binary_crossentropy: 0.6931\n",
      "8/8 [==============================] - 1s 178ms/step - loss: 1.1636 - accuracy: 0.4840 - binary_crossentropy: 0.6931\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Female\\Run-5\\assets\n",
      "--- Starting trial: run-6\n",
      "{'lambda': 0.1}\n",
      "Epoch 1/20\n",
      "32/32 - 49s - loss: 20.6230 - accuracy: 0.5025 - binary_crossentropy: 0.7715 - val_loss: 2.8948 - val_accuracy: 0.5480 - val_binary_crossentropy: 0.6931\n",
      "Epoch 2/20\n",
      "32/32 - 48s - loss: 1.7527 - accuracy: 0.5170 - binary_crossentropy: 0.6931 - val_loss: 1.1819 - val_accuracy: 0.5160 - val_binary_crossentropy: 0.6931\n",
      "Epoch 3/20\n",
      "32/32 - 48s - loss: 1.0373 - accuracy: 0.5060 - binary_crossentropy: 0.6931 - val_loss: 0.9320 - val_accuracy: 0.4840 - val_binary_crossentropy: 0.6931\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 2.8948 - accuracy: 0.5480 - binary_crossentropy: 0.6931\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Type_Female\\Run-6\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for lambda_reg in HP_LAMBDA_REG.domain.values:\n",
    "\n",
    "    hparams = {\n",
    "        HP_LAMBDA_REG: lambda_reg\n",
    "    }\n",
    "                    \n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run('Logs_Practical/Model Trousers_and_Jeans_Type_Female/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 3172."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Trousers_and_Jeans_Type_Female/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Trousers_and_Jeans_Type_Female/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

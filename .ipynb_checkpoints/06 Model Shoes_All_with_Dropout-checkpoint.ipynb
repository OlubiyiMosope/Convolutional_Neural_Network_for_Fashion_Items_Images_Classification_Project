{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "Here, we'll deal the Shoes category. We'll be building a model to classify all 11 sub categories at once.\n",
    "\n",
    "###### Data Augmentation:\n",
    "All the images of shoes face left to right, but in deployment, the model might encounter images that face the opposite orientation, or some other non-side view, and we'll want the model to recognize these too.  \n",
    "To resolve this, data augumentation will be performed on the shoes data by flipping all the images and concatenating the flipped images to the shoes dataset.\n",
    "\n",
    "###### Dropout:\n",
    "The dropout technique for improving model performance will be employed in this model.  \n",
    "Dropout refers to the technique in which some of the outputs of a dense layer are randomly set to zero, thus helping individual neurons to learn more general patterns about the data set.  \n",
    "\n",
    "It is implemented by adding a dropout layer to the network. The parameter  set for this layer are proportions of the output to drop.  \n",
    "Typically, the range of proportions is anything less than 50%.\n",
    "Different proportion will be tested and fed as hyperparameters into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import environ # To get the file path of the datasets location from Windows environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "dataset_path = environ.get('CNN_Practical_Dataset_Path')\n",
    "\n",
    "data_train = np.load(dataset_path + \"/Shoes - All - Train.npz\")\n",
    "data_val = np.load(dataset_path + \"/Shoes - All - Validation.npz\")\n",
    "data_test = np.load(dataset_path + \"/Shoes - All - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_val['images']\n",
    "labels_val = data_val['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4959, 120, 90, 3)\n",
      "(619, 120, 90, 3)\n",
      "(619, 120, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the datasets\n",
    "print(images_train.shape)\n",
    "print(images_val.shape)\n",
    "print(images_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the labels of the dataset.\n",
    "np.unique(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the images right to left using the columns axis.\n",
    "images_train_flipped = np.flip(images_train, axis=2)\n",
    "images_val_flipped = np.flip(images_val, axis=2)\n",
    "images_test_flipped = np.flip(images_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the flipped dataset with the original one to obtain the new dataset\n",
    "images_train = np.concatenate( (images_train, images_train_flipped) )\n",
    "labels_train = np.concatenate( (labels_train, labels_train) )\n",
    "\n",
    "images_val = np.concatenate( (images_val, images_val_flipped) )\n",
    "labels_val = np.concatenate( (labels_val, labels_val) )\n",
    "\n",
    "images_test = np.concatenate( (images_test, images_test_flipped) )\n",
    "labels_test = np.concatenate( (labels_test, labels_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9918, 120, 90, 3)\n",
      "(4959, 120, 90, 3) \n",
      "\n",
      "(1238, 120, 90, 3)\n",
      "(619, 120, 90, 3) \n",
      "\n",
      "(1238, 120, 90, 3)\n",
      "(619, 120, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the datasets\n",
    "print(images_train.shape)\n",
    "print(images_train_flipped.shape,'\\n')\n",
    "print(images_val.shape)\n",
    "print(images_val_flipped.shape,'\\n')\n",
    "print(images_test.shape)\n",
    "print(images_test_flipped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hypermatarest we would test and their range\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.8])) \n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs_Practical/Model Shoes_All_with_Dropout/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_DROPOUT],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some constants/hyperparameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "FILTER_SIZE = 5\n",
    "FILTER_NUM = 64\n",
    "DENSE_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Boots  Male', 'Trainers/Sneakers Male', 'Sandals/Flip flops/Slippers Male', 'Formal Shoes Male', 'Others Male',\n",
    "                'Boots Female', 'Trainers/Sneakers Female', 'Ballerina shoes Female', 'High heels Female', 'Sandals/Flip flops/Slippers Female', 'Others Female']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it\n",
    "\n",
    "Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(FILTER_NUM, FILTER_SIZE, activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(FILTER_NUM, FILTER_SIZE, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(DENSE_SIZE, activation='relu'),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(11)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "      \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        \n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "        \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs_Practical\\\\Model Shoes_All_with_Dropout\\\\fit\\\\\" + \"run-{}\".format(session_num)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the per_epoch callback.\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models\\Model Shoes_All_with_Dropout\\Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'dropout': 0.0}\n",
      "Epoch 1/20\n",
      "155/155 - 194s - loss: 1.8883 - accuracy: 0.4109 - val_loss: 1.7639 - val_accuracy: 0.4709\n",
      "Epoch 2/20\n",
      "155/155 - 195s - loss: 1.3122 - accuracy: 0.5674 - val_loss: 1.0911 - val_accuracy: 0.6405\n",
      "Epoch 3/20\n",
      "155/155 - 194s - loss: 0.8673 - accuracy: 0.6974 - val_loss: 1.0082 - val_accuracy: 0.6737\n",
      "Epoch 4/20\n",
      "155/155 - 249s - loss: 0.7289 - accuracy: 0.7369 - val_loss: 0.9675 - val_accuracy: 0.6987\n",
      "Epoch 5/20\n",
      "155/155 - 202s - loss: 0.6104 - accuracy: 0.7760 - val_loss: 0.9281 - val_accuracy: 0.6931\n",
      "Epoch 6/20\n",
      "155/155 - 1796s - loss: 0.5031 - accuracy: 0.8131 - val_loss: 0.8412 - val_accuracy: 0.7399\n",
      "Epoch 7/20\n",
      "155/155 - 192s - loss: 0.4182 - accuracy: 0.8457 - val_loss: 0.8830 - val_accuracy: 0.7447\n",
      "Epoch 8/20\n",
      "155/155 - 206s - loss: 0.3639 - accuracy: 0.8648 - val_loss: 0.8927 - val_accuracy: 0.7617\n",
      "39/39 [==============================] - 6s 154ms/step - loss: 0.8412 - accuracy: 0.7399\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Shoes_All_with_Dropout\\Run-1\\assets\n",
      "--- Starting trial: run-2\n",
      "{'dropout': 0.1}\n",
      "Epoch 1/20\n",
      "155/155 - 233s - loss: 1.4952 - accuracy: 0.5200 - val_loss: 1.0140 - val_accuracy: 0.6535\n",
      "Epoch 2/20\n",
      "155/155 - 267s - loss: 0.9025 - accuracy: 0.6934 - val_loss: 0.8700 - val_accuracy: 0.6931\n",
      "Epoch 3/20\n",
      "155/155 - 273s - loss: 0.7261 - accuracy: 0.7425 - val_loss: 0.8991 - val_accuracy: 0.6882\n",
      "Epoch 4/20\n",
      "155/155 - 269s - loss: 0.6283 - accuracy: 0.7794 - val_loss: 0.7819 - val_accuracy: 0.7342\n",
      "Epoch 5/20\n",
      "155/155 - 260s - loss: 0.5019 - accuracy: 0.8119 - val_loss: 0.7681 - val_accuracy: 0.7666\n",
      "Epoch 6/20\n",
      "155/155 - 265s - loss: 0.3973 - accuracy: 0.8558 - val_loss: 0.7800 - val_accuracy: 0.7633\n",
      "Epoch 7/20\n",
      "155/155 - 262s - loss: 0.3061 - accuracy: 0.8872 - val_loss: 0.8475 - val_accuracy: 0.7577\n",
      "39/39 [==============================] - 8s 203ms/step - loss: 0.7681 - accuracy: 0.7666\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Shoes_All_with_Dropout\\Run-2\\assets\n",
      "--- Starting trial: run-3\n",
      "{'dropout': 0.2}\n",
      "Epoch 1/20\n",
      "155/155 - 254s - loss: 1.6134 - accuracy: 0.5058 - val_loss: 1.0549 - val_accuracy: 0.6494\n",
      "Epoch 2/20\n",
      "155/155 - 251s - loss: 0.9136 - accuracy: 0.6837 - val_loss: 1.0079 - val_accuracy: 0.6535\n",
      "Epoch 3/20\n",
      "155/155 - 252s - loss: 0.7252 - accuracy: 0.7414 - val_loss: 0.7897 - val_accuracy: 0.7019\n",
      "Epoch 4/20\n",
      "155/155 - 252s - loss: 0.5976 - accuracy: 0.7809 - val_loss: 0.7707 - val_accuracy: 0.7197\n",
      "Epoch 5/20\n",
      "155/155 - 252s - loss: 0.5039 - accuracy: 0.8154 - val_loss: 0.7235 - val_accuracy: 0.7423\n",
      "Epoch 6/20\n",
      "155/155 - 250s - loss: 0.4162 - accuracy: 0.8491 - val_loss: 0.8654 - val_accuracy: 0.7391\n",
      "Epoch 7/20\n",
      "155/155 - 250s - loss: 0.3441 - accuracy: 0.8751 - val_loss: 0.8372 - val_accuracy: 0.7698\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 0.7235 - accuracy: 0.7423\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Shoes_All_with_Dropout\\Run-3\\assets\n",
      "--- Starting trial: run-4\n",
      "{'dropout': 0.3}\n",
      "Epoch 1/20\n",
      "155/155 - 226s - loss: 1.7483 - accuracy: 0.4748 - val_loss: 1.2440 - val_accuracy: 0.6171\n",
      "Epoch 2/20\n",
      "155/155 - 210s - loss: 1.0385 - accuracy: 0.6538 - val_loss: 0.9764 - val_accuracy: 0.6607\n",
      "Epoch 3/20\n",
      "155/155 - 223s - loss: 0.8274 - accuracy: 0.7130 - val_loss: 0.8756 - val_accuracy: 0.6922\n",
      "Epoch 4/20\n",
      "155/155 - 2352s - loss: 0.7606 - accuracy: 0.7293 - val_loss: 0.9236 - val_accuracy: 0.6898\n",
      "Epoch 5/20\n",
      "155/155 - 198s - loss: 0.6790 - accuracy: 0.7548 - val_loss: 0.8714 - val_accuracy: 0.7100\n",
      "Epoch 6/20\n",
      "155/155 - 193s - loss: 0.5350 - accuracy: 0.8057 - val_loss: 0.8152 - val_accuracy: 0.7367\n",
      "Epoch 7/20\n",
      "155/155 - 228s - loss: 0.4457 - accuracy: 0.8339 - val_loss: 0.8398 - val_accuracy: 0.7569\n",
      "Epoch 8/20\n",
      "155/155 - 251s - loss: 0.3843 - accuracy: 0.8586 - val_loss: 0.8665 - val_accuracy: 0.7625\n",
      "39/39 [==============================] - 8s 200ms/step - loss: 0.8152 - accuracy: 0.7367\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Shoes_All_with_Dropout\\Run-4\\assets\n",
      "--- Starting trial: run-5\n",
      "{'dropout': 0.4}\n",
      "Epoch 1/20\n",
      "155/155 - 213s - loss: 1.7042 - accuracy: 0.4604 - val_loss: 1.2853 - val_accuracy: 0.5913\n",
      "Epoch 2/20\n",
      "155/155 - 4408s - loss: 1.0212 - accuracy: 0.6507 - val_loss: 0.9538 - val_accuracy: 0.6809\n",
      "Epoch 3/20\n",
      "155/155 - 199s - loss: 0.8448 - accuracy: 0.7031 - val_loss: 0.8549 - val_accuracy: 0.7124\n",
      "Epoch 4/20\n",
      "155/155 - 201s - loss: 0.6793 - accuracy: 0.7535 - val_loss: 0.8187 - val_accuracy: 0.7141\n",
      "Epoch 5/20\n",
      "155/155 - 201s - loss: 0.5574 - accuracy: 0.7982 - val_loss: 0.7976 - val_accuracy: 0.7205\n",
      "Epoch 6/20\n",
      "155/155 - 201s - loss: 0.4896 - accuracy: 0.8208 - val_loss: 0.8015 - val_accuracy: 0.7431\n",
      "Epoch 7/20\n",
      "155/155 - 214s - loss: 0.4230 - accuracy: 0.8428 - val_loss: 0.7973 - val_accuracy: 0.7544\n",
      "Epoch 8/20\n",
      "155/155 - 233s - loss: 0.3592 - accuracy: 0.8651 - val_loss: 0.8835 - val_accuracy: 0.7480\n",
      "Epoch 9/20\n",
      "155/155 - 206s - loss: 0.3027 - accuracy: 0.8902 - val_loss: 0.8507 - val_accuracy: 0.7754\n",
      "39/39 [==============================] - 9s 221ms/step - loss: 0.7973 - accuracy: 0.7544\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Shoes_All_with_Dropout\\Run-5\\assets\n",
      "--- Starting trial: run-6\n",
      "{'dropout': 0.5}\n",
      "Epoch 1/20\n",
      "155/155 - 272s - loss: 1.5785 - accuracy: 0.5167 - val_loss: 1.0930 - val_accuracy: 0.6422\n",
      "Epoch 2/20\n",
      "155/155 - 211s - loss: 0.9385 - accuracy: 0.6839 - val_loss: 0.9444 - val_accuracy: 0.6656\n",
      "Epoch 3/20\n",
      "155/155 - 244s - loss: 0.7717 - accuracy: 0.7261 - val_loss: 0.8464 - val_accuracy: 0.6931\n",
      "Epoch 4/20\n",
      "155/155 - 253s - loss: 0.6368 - accuracy: 0.7660 - val_loss: 0.7510 - val_accuracy: 0.7286\n",
      "Epoch 5/20\n",
      "155/155 - 224s - loss: 0.5470 - accuracy: 0.7990 - val_loss: 0.7743 - val_accuracy: 0.7375\n",
      "Epoch 6/20\n",
      "155/155 - 250s - loss: 0.4724 - accuracy: 0.8259 - val_loss: 1.1386 - val_accuracy: 0.6559\n",
      "39/39 [==============================] - 9s 225ms/step - loss: 0.7510 - accuracy: 0.7286\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Shoes_All_with_Dropout\\Run-6\\assets\n",
      "--- Starting trial: run-7\n",
      "{'dropout': 0.8}\n",
      "Epoch 1/20\n",
      "155/155 - 266s - loss: 1.8078 - accuracy: 0.4171 - val_loss: 1.3117 - val_accuracy: 0.5444\n",
      "Epoch 2/20\n",
      "155/155 - 259s - loss: 1.3170 - accuracy: 0.5731 - val_loss: 1.1526 - val_accuracy: 0.6365\n",
      "Epoch 3/20\n",
      "155/155 - 265s - loss: 1.1112 - accuracy: 0.6308 - val_loss: 0.8718 - val_accuracy: 0.6817\n",
      "Epoch 4/20\n",
      "155/155 - 259s - loss: 0.8903 - accuracy: 0.6876 - val_loss: 0.8344 - val_accuracy: 0.7027\n",
      "Epoch 5/20\n",
      "155/155 - 207s - loss: 0.8304 - accuracy: 0.7104 - val_loss: 0.8834 - val_accuracy: 0.6874\n",
      "Epoch 6/20\n",
      "155/155 - 240s - loss: 0.7379 - accuracy: 0.7400 - val_loss: 0.7661 - val_accuracy: 0.7205\n",
      "Epoch 7/20\n",
      "155/155 - 259s - loss: 0.6654 - accuracy: 0.7564 - val_loss: 0.7135 - val_accuracy: 0.7431\n",
      "Epoch 8/20\n",
      "155/155 - 257s - loss: 0.6083 - accuracy: 0.7781 - val_loss: 0.6895 - val_accuracy: 0.7520\n",
      "Epoch 9/20\n",
      "155/155 - 260s - loss: 0.6411 - accuracy: 0.7696 - val_loss: 0.8233 - val_accuracy: 0.7213\n",
      "Epoch 10/20\n",
      "155/155 - 221s - loss: 0.6845 - accuracy: 0.7566 - val_loss: 0.7964 - val_accuracy: 0.7326\n",
      "39/39 [==============================] - 6s 150ms/step - loss: 0.6895 - accuracy: 0.7520\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Shoes_All_with_Dropout\\Run-7\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for dropout in HP_DROPOUT.domain.values:\n",
    "\n",
    "    hparams = {\n",
    "        HP_DROPOUT: dropout\n",
    "    }\n",
    "                    \n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run('Logs_Practical/Model Shoes_All_with_Dropout/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "    session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models\\Model Shoes_All_with_Dropout\\Run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 6s 154ms/step - loss: 0.7488 - accuracy: 0.1018\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7488. Test accuracy: 10.18%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15812), started 0:01:20 ago. (Use '!kill 15812' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-67e75268c9dd90b9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-67e75268c9dd90b9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Shoes_All_with_Dropout/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5844), started 0:01:35 ago. (Use '!kill 5844' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bffc858a0c82db2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bffc858a0c82db2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Shoes_All_with_Dropout/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

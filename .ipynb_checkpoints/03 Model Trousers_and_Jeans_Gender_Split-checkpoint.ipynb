{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on the Trousers and Jeans category data.  \n",
    "This category has 4 sub-categories: Male Trousers, Female Trousers, Male Jeans, Female Jeans.\n",
    "\n",
    "Approach 2 will be employed to perform the classification task of splitting the data these sub-categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import environ # To get the file path of the datasets location from Windows environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets from the path stored in the operating system's environment variable\n",
    "dataset_path = environ.get('CNN_Practical_Dataset_Path')\n",
    "\n",
    "data_train = np.load(dataset_path + \"/Trousers & Jeans - All - Train.npz\")\n",
    "data_validation = np.load(dataset_path + \"/Trousers & Jeans - All - Validation.npz\")\n",
    "data_test = np.load(dataset_path + \"/Trousers & Jeans - All - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'labels', 'genders']\n",
      "['images', 'labels', 'genders']\n",
      "['images', 'labels', 'genders']\n"
     ]
    }
   ],
   "source": [
    "print(list(data_train.keys()))\n",
    "print(list(data_validation.keys()))\n",
    "print(list(data_test.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['genders']\n",
    "\n",
    "images_val = data_validation['images']\n",
    "labels_val = data_validation['genders']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['genders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the pixel values of all images\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4004, 120, 90, 3)\n",
      "(500, 120, 90, 3)\n",
      "(500, 120, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape)\n",
    "print(images_val.shape)\n",
    "print(images_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4004,)\n",
      "(500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train.shape)\n",
    "print(labels_val.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "DENSE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_SIZE_1 = hp.HParam('filter_size_1', hp.Discrete([5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filters_number', hp.Discrete([64,96]))\n",
    "HP_FILTER_SIZE_2 = hp.HParam('filter_size_2', hp.Discrete([3,5]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs_Practical/Model Trousers_and_Jeans_Gender_Split/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE_1, HP_FILTER_NUM, HP_FILTER_SIZE_2],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE_1], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_FILTER_NUM], 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(DENSE_SIZE, activation='relu'),\n",
    "        tf.keras.layers.Dense(2)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs_Practical\\\\Model Trousers_and_Jeans_Gender_Split\\\\fit\\\\\" + \"run-{}\".format(session_num)\n",
    "    \n",
    "    # Defining function to plot the confusion matrix\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        \n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "    \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Male', 'Female'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val,labels_val),\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the results\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size_1': 5, 'filters_number': 64, 'filter_size_2': 3}\n",
      "Epoch 1/20\n",
      "126/126 - 59s - loss: 0.5872 - accuracy: 0.7318 - val_loss: 0.4522 - val_accuracy: 0.7780\n",
      "Epoch 2/20\n",
      "126/126 - 59s - loss: 0.4314 - accuracy: 0.8054 - val_loss: 0.7860 - val_accuracy: 0.6880\n",
      "Epoch 3/20\n",
      "126/126 - 56s - loss: 0.3740 - accuracy: 0.8404 - val_loss: 0.3958 - val_accuracy: 0.8420\n",
      "Epoch 4/20\n",
      "126/126 - 61s - loss: 0.3317 - accuracy: 0.8596 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
      "Epoch 5/20\n",
      "126/126 - 70s - loss: 0.3150 - accuracy: 0.8679 - val_loss: 0.3703 - val_accuracy: 0.8380\n",
      "Epoch 6/20\n",
      "126/126 - 77s - loss: 0.2871 - accuracy: 0.8826 - val_loss: 0.3579 - val_accuracy: 0.8380\n",
      "Epoch 7/20\n",
      "126/126 - 76s - loss: 0.2762 - accuracy: 0.8836 - val_loss: 0.3777 - val_accuracy: 0.8520\n",
      "Epoch 8/20\n",
      "126/126 - 74s - loss: 0.2417 - accuracy: 0.9028 - val_loss: 0.3158 - val_accuracy: 0.8560\n",
      "Epoch 9/20\n",
      "126/126 - 78s - loss: 0.2222 - accuracy: 0.9086 - val_loss: 0.4629 - val_accuracy: 0.8100\n",
      "Epoch 10/20\n",
      "126/126 - 70s - loss: 0.2352 - accuracy: 0.9058 - val_loss: 0.4461 - val_accuracy: 0.8380\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 0.3158 - accuracy: 0.8560\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-1\\assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size_1': 5, 'filters_number': 64, 'filter_size_2': 5}\n",
      "Epoch 1/20\n",
      "126/126 - 76s - loss: 0.5989 - accuracy: 0.7340 - val_loss: 0.4900 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "126/126 - 69s - loss: 0.4159 - accuracy: 0.8179 - val_loss: 0.4230 - val_accuracy: 0.8200\n",
      "Epoch 3/20\n",
      "126/126 - 76s - loss: 0.3647 - accuracy: 0.8384 - val_loss: 0.5368 - val_accuracy: 0.7660\n",
      "Epoch 4/20\n",
      "126/126 - 70s - loss: 0.3494 - accuracy: 0.8529 - val_loss: 0.4124 - val_accuracy: 0.8040\n",
      "Epoch 5/20\n",
      "126/126 - 73s - loss: 0.3097 - accuracy: 0.8711 - val_loss: 0.4047 - val_accuracy: 0.8440\n",
      "Epoch 6/20\n",
      "126/126 - 74s - loss: 0.2894 - accuracy: 0.8809 - val_loss: 0.3545 - val_accuracy: 0.8400\n",
      "Epoch 7/20\n",
      "126/126 - 68s - loss: 0.2585 - accuracy: 0.8926 - val_loss: 0.3810 - val_accuracy: 0.8220\n",
      "Epoch 8/20\n",
      "126/126 - 74s - loss: 0.2258 - accuracy: 0.9068 - val_loss: 0.3553 - val_accuracy: 0.8620\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.3545 - accuracy: 0.8400\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-2\\assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size_1': 5, 'filters_number': 96, 'filter_size_2': 3}\n",
      "Epoch 1/20\n",
      "126/126 - 112s - loss: 0.7972 - accuracy: 0.7028 - val_loss: 0.5112 - val_accuracy: 0.7360\n",
      "Epoch 2/20\n",
      "126/126 - 105s - loss: 0.4398 - accuracy: 0.8042 - val_loss: 0.4538 - val_accuracy: 0.7880\n",
      "Epoch 3/20\n",
      "126/126 - 106s - loss: 0.3863 - accuracy: 0.8394 - val_loss: 0.4602 - val_accuracy: 0.7880\n",
      "Epoch 4/20\n",
      "126/126 - 109s - loss: 0.3645 - accuracy: 0.8492 - val_loss: 0.4059 - val_accuracy: 0.8260\n",
      "Epoch 5/20\n",
      "126/126 - 107s - loss: 0.3442 - accuracy: 0.8504 - val_loss: 0.4086 - val_accuracy: 0.7920\n",
      "Epoch 6/20\n",
      "126/126 - 110s - loss: 0.3121 - accuracy: 0.8671 - val_loss: 0.3853 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      "126/126 - 108s - loss: 0.2811 - accuracy: 0.8859 - val_loss: 0.3611 - val_accuracy: 0.8600\n",
      "Epoch 8/20\n",
      "126/126 - 107s - loss: 0.2508 - accuracy: 0.8999 - val_loss: 0.3339 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "126/126 - 116s - loss: 0.2653 - accuracy: 0.8916 - val_loss: 0.3706 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "126/126 - 107s - loss: 0.2333 - accuracy: 0.9048 - val_loss: 0.3165 - val_accuracy: 0.8780\n",
      "Epoch 11/20\n",
      "126/126 - 109s - loss: 0.2048 - accuracy: 0.9221 - val_loss: 0.4376 - val_accuracy: 0.8560\n",
      "Epoch 12/20\n",
      "126/126 - 110s - loss: 0.1957 - accuracy: 0.9263 - val_loss: 0.3059 - val_accuracy: 0.9040\n",
      "Epoch 13/20\n",
      "126/126 - 109s - loss: 0.1696 - accuracy: 0.9348 - val_loss: 0.3201 - val_accuracy: 0.8920\n",
      "Epoch 14/20\n",
      "126/126 - 112s - loss: 0.1771 - accuracy: 0.9308 - val_loss: 0.3637 - val_accuracy: 0.8620\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.3059 - accuracy: 0.9040\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-3\\assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size_1': 5, 'filters_number': 96, 'filter_size_2': 5}\n",
      "Epoch 1/20\n",
      "126/126 - 111s - loss: 0.7240 - accuracy: 0.7180 - val_loss: 0.5313 - val_accuracy: 0.7260\n",
      "Epoch 2/20\n",
      "126/126 - 113s - loss: 0.4226 - accuracy: 0.8142 - val_loss: 0.6932 - val_accuracy: 0.7060\n",
      "Epoch 3/20\n",
      "126/126 - 113s - loss: 0.3546 - accuracy: 0.8504 - val_loss: 0.4040 - val_accuracy: 0.8160\n",
      "Epoch 4/20\n",
      "126/126 - 123s - loss: 0.3421 - accuracy: 0.8569 - val_loss: 0.4185 - val_accuracy: 0.8040\n",
      "Epoch 5/20\n",
      "126/126 - 116s - loss: 0.3045 - accuracy: 0.8744 - val_loss: 0.3593 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "126/126 - 123s - loss: 0.2871 - accuracy: 0.8864 - val_loss: 0.3901 - val_accuracy: 0.8260\n",
      "Epoch 7/20\n",
      "126/126 - 113s - loss: 0.2701 - accuracy: 0.8906 - val_loss: 0.3574 - val_accuracy: 0.8580\n",
      "Epoch 8/20\n",
      "126/126 - 110s - loss: 0.2314 - accuracy: 0.9066 - val_loss: 0.3343 - val_accuracy: 0.8880\n",
      "Epoch 9/20\n",
      "126/126 - 115s - loss: 0.2144 - accuracy: 0.9111 - val_loss: 0.3405 - val_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "126/126 - 112s - loss: 0.2153 - accuracy: 0.9143 - val_loss: 0.3111 - val_accuracy: 0.9100\n",
      "Epoch 11/20\n",
      "126/126 - 114s - loss: 0.1879 - accuracy: 0.9258 - val_loss: 0.3262 - val_accuracy: 0.8900\n",
      "Epoch 12/20\n",
      "126/126 - 114s - loss: 0.1876 - accuracy: 0.9253 - val_loss: 0.3116 - val_accuracy: 0.9060\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.3111 - accuracy: 0.9100\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-4\\assets\n",
      "--- Starting trial: run-5\n",
      "{'filter_size_1': 7, 'filters_number': 64, 'filter_size_2': 3}\n",
      "Epoch 1/20\n",
      "126/126 - 80s - loss: 0.6637 - accuracy: 0.7240 - val_loss: 0.4901 - val_accuracy: 0.7340\n",
      "Epoch 2/20\n",
      "126/126 - 85s - loss: 0.4053 - accuracy: 0.8239 - val_loss: 0.4586 - val_accuracy: 0.7760\n",
      "Epoch 3/20\n",
      "126/126 - 80s - loss: 0.3565 - accuracy: 0.8511 - val_loss: 0.3952 - val_accuracy: 0.8300\n",
      "Epoch 4/20\n",
      "126/126 - 85s - loss: 0.3236 - accuracy: 0.8664 - val_loss: 0.3710 - val_accuracy: 0.8100\n",
      "Epoch 5/20\n",
      "126/126 - 80s - loss: 0.3128 - accuracy: 0.8659 - val_loss: 0.3710 - val_accuracy: 0.8220\n",
      "Epoch 6/20\n",
      "126/126 - 88s - loss: 0.2803 - accuracy: 0.8894 - val_loss: 0.3549 - val_accuracy: 0.8500\n",
      "Epoch 7/20\n",
      "126/126 - 88s - loss: 0.2553 - accuracy: 0.8966 - val_loss: 0.3248 - val_accuracy: 0.8820\n",
      "Epoch 8/20\n",
      "126/126 - 90s - loss: 0.2350 - accuracy: 0.9018 - val_loss: 0.3060 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "126/126 - 83s - loss: 0.2149 - accuracy: 0.9151 - val_loss: 0.3712 - val_accuracy: 0.8680\n",
      "Epoch 10/20\n",
      "126/126 - 81s - loss: 0.2218 - accuracy: 0.9103 - val_loss: 0.3079 - val_accuracy: 0.8880\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.3060 - accuracy: 0.8720\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-5\\assets\n",
      "--- Starting trial: run-6\n",
      "{'filter_size_1': 7, 'filters_number': 64, 'filter_size_2': 5}\n",
      "Epoch 1/20\n",
      "126/126 - 87s - loss: 0.6081 - accuracy: 0.7283 - val_loss: 0.4662 - val_accuracy: 0.7540\n",
      "Epoch 2/20\n",
      "126/126 - 86s - loss: 0.3908 - accuracy: 0.8364 - val_loss: 0.4389 - val_accuracy: 0.8300\n",
      "Epoch 3/20\n",
      "126/126 - 81s - loss: 0.3440 - accuracy: 0.8511 - val_loss: 0.3779 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "126/126 - 81s - loss: 0.3030 - accuracy: 0.8809 - val_loss: 0.3722 - val_accuracy: 0.8540\n",
      "Epoch 5/20\n",
      "126/126 - 82s - loss: 0.3156 - accuracy: 0.8714 - val_loss: 0.4474 - val_accuracy: 0.8180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "126/126 - 85s - loss: 0.2696 - accuracy: 0.8926 - val_loss: 0.3270 - val_accuracy: 0.8780\n",
      "Epoch 7/20\n",
      "126/126 - 84s - loss: 0.2338 - accuracy: 0.9081 - val_loss: 0.3215 - val_accuracy: 0.8720\n",
      "Epoch 8/20\n",
      "126/126 - 81s - loss: 0.2179 - accuracy: 0.9093 - val_loss: 0.2870 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "126/126 - 81s - loss: 0.2125 - accuracy: 0.9163 - val_loss: 0.3349 - val_accuracy: 0.8960\n",
      "Epoch 10/20\n",
      "126/126 - 83s - loss: 0.1986 - accuracy: 0.9266 - val_loss: 0.3139 - val_accuracy: 0.8800\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.2870 - accuracy: 0.9000\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-6\\assets\n",
      "--- Starting trial: run-7\n",
      "{'filter_size_1': 7, 'filters_number': 96, 'filter_size_2': 3}\n",
      "Epoch 1/20\n",
      "126/126 - 129s - loss: 0.6786 - accuracy: 0.6733 - val_loss: 0.5041 - val_accuracy: 0.7200\n",
      "Epoch 2/20\n",
      "126/126 - 138s - loss: 0.4242 - accuracy: 0.8097 - val_loss: 0.4219 - val_accuracy: 0.8120\n",
      "Epoch 3/20\n",
      "126/126 - 139s - loss: 0.3777 - accuracy: 0.8307 - val_loss: 0.3920 - val_accuracy: 0.8300\n",
      "Epoch 4/20\n",
      "126/126 - 147s - loss: 0.3518 - accuracy: 0.8506 - val_loss: 0.3803 - val_accuracy: 0.8460\n",
      "Epoch 5/20\n",
      "126/126 - 141s - loss: 0.3116 - accuracy: 0.8669 - val_loss: 0.4147 - val_accuracy: 0.8180\n",
      "Epoch 6/20\n",
      "126/126 - 139s - loss: 0.2895 - accuracy: 0.8834 - val_loss: 0.4114 - val_accuracy: 0.8280\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.3803 - accuracy: 0.8460\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-7\\assets\n",
      "--- Starting trial: run-8\n",
      "{'filter_size_1': 7, 'filters_number': 96, 'filter_size_2': 5}\n",
      "Epoch 1/20\n",
      "126/126 - 137s - loss: 0.6020 - accuracy: 0.7065 - val_loss: 0.4699 - val_accuracy: 0.7920\n",
      "Epoch 2/20\n",
      "126/126 - 148s - loss: 0.4156 - accuracy: 0.8119 - val_loss: 0.4311 - val_accuracy: 0.7780\n",
      "Epoch 3/20\n",
      "126/126 - 136s - loss: 0.3737 - accuracy: 0.8404 - val_loss: 0.4243 - val_accuracy: 0.8260\n",
      "Epoch 4/20\n",
      "126/126 - 128s - loss: 0.3353 - accuracy: 0.8561 - val_loss: 0.4077 - val_accuracy: 0.8380\n",
      "Epoch 5/20\n",
      "126/126 - 123s - loss: 0.3079 - accuracy: 0.8666 - val_loss: 0.4994 - val_accuracy: 0.7800\n",
      "Epoch 6/20\n",
      "126/126 - 123s - loss: 0.2698 - accuracy: 0.8901 - val_loss: 0.4161 - val_accuracy: 0.8440\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.4077 - accuracy: 0.8380\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-8\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size_1 in HP_FILTER_SIZE_1.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "        for filter_size_2 in HP_FILTER_SIZE_2.domain.values:\n",
    "                        \n",
    "                hparams = {\n",
    "                    HP_FILTER_SIZE_1: filter_size_1,\n",
    "                    HP_FILTER_NUM: filter_num,\n",
    "                    HP_FILTER_SIZE_2: filter_size_2,\n",
    "                   }\n",
    "\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run('Logs_Practical/Model Trousers_and_Jeans_Gender_Split/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models\\Model Trousers_and_Jeans_Gender_Split\\Run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 127ms/step - loss: 0.3075 - accuracy: 0.4760\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3075. Test accuracy: 47.60%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14052), started 0:01:57 ago. (Use '!kill 14052' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b4ddd8385e9b529c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b4ddd8385e9b529c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Trousers_and_Jeans_Gender_Split/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 780), started 0:01:33 ago. (Use '!kill 780' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fa66ada48bba2019\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fa66ada48bba2019\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Trousers_and_Jeans_Gender_Split/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

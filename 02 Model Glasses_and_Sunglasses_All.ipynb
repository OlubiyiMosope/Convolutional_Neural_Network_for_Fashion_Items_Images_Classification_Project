{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc326b52",
   "metadata": {},
   "source": [
    "## Description:\n",
    "Having solved the primary classification task which split the data into 3 main categories of Glasses and Sunglasses, Trousers and Jeans, and Shoes, the next step is to deal with the Glasses/Sunglasses category and its sub-categories.\n",
    "\n",
    "The objective is to create a model to classify the data into the two subclasses: optical glasses and sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9019b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import environ # To get the file path of the datasets location from Windows environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2022d",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79eac6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets from the path stored in the operating system's environment variable\n",
    "dataset_path = environ.get('CNN_Practical_Dataset_Path')\n",
    "\n",
    "data_train = np.load(dataset_path + \"/Glasses & Sunglasses - Train.npz\")\n",
    "data_validation = np.load(dataset_path + \"/Glasses & Sunglasses - Validation.npz\")\n",
    "data_test = np.load(dataset_path + \"/Glasses & Sunglasses - Test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1358a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'labels']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c662abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the arrays from the imported data\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_validation['images']\n",
    "labels_val = data_validation['labels']\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b4232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the pixel values of all images\n",
    "images_train = images_train/255.0\n",
    "images_val = images_val/255.0\n",
    "images_test = images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f12341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4002, 120, 90, 3)\n",
      "(500, 120, 90, 3)\n",
      "(500, 120, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape)\n",
    "print(images_val.shape)\n",
    "print(images_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df654595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4002,)\n",
      "(500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(labels_train.shape)\n",
    "print(labels_val.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa86c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ae53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4abde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3,5]))   # [3,5]\n",
    "HP_FILTER_NUM = hp.HParam('filter_num', hp.Discrete([64,96]))   # [64,96]\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer(r'Logs_Practical/Model Glasses_and_Sunglasses/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_FILTER_SIZE, HP_FILTER_NUM],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b927517",
   "metadata": {},
   "source": [
    "## Creating the model and training it\n",
    "\n",
    "Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d76c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of the CNN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=hparams[HP_FILTER_NUM], kernel_size=hparams[HP_FILTER_SIZE], activation='relu', input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(filters=hparams[HP_FILTER_NUM], kernel_size=hparams[HP_FILTER_SIZE], activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"Logs_Practical\\\\Model Glasses_and_Sunglasses\\\\fit\\\\\" + \"run-0{}\".format(session_num)\n",
    "    \n",
    "    # Defining function to plot the confusion matrix\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "          cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "          class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "        \n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "        returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "\n",
    "    # Defining a file writer for Confusion Matrix logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')     \n",
    "    \n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Optical glasses', 'Sunglasses'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "    \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='auto',\n",
    "            min_delta=0,\n",
    "            patience=2,\n",
    "            verbose=2,\n",
    "            restore_best_weights=False,\n",
    "        )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data=(images_val, labels_val),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models\\Model Glasses_and_Sunglasses\\Run-0{}\".format(session_num))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15fb78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d80f8ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f068febc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size': 3, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "201/201 - 55s - loss: 0.7085 - accuracy: 0.4710 - val_loss: 0.6931 - val_accuracy: 0.4640\n",
      "Epoch 2/15\n",
      "201/201 - 53s - loss: 0.6931 - accuracy: 0.5027 - val_loss: 0.6931 - val_accuracy: 0.4840\n",
      "Epoch 3/15\n",
      "201/201 - 40s - loss: 0.6931 - accuracy: 0.5155 - val_loss: 0.6931 - val_accuracy: 0.5060\n",
      "Epoch 4/15\n",
      "201/201 - 40s - loss: 0.6931 - accuracy: 0.5310 - val_loss: 0.6931 - val_accuracy: 0.5340\n",
      "Epoch 00004: early stopping\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.6931 - accuracy: 0.5340\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\anaconda3-TF2.0\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Glasses_and_Sunglasses\\Run-01\\assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size': 3, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "201/201 - 65s - loss: 0.7134 - accuracy: 0.5752 - val_loss: 0.6931 - val_accuracy: 0.6060\n",
      "Epoch 2/15\n",
      "201/201 - 66s - loss: 0.6931 - accuracy: 0.5735 - val_loss: 0.6931 - val_accuracy: 0.5640\n",
      "Epoch 3/15\n",
      "201/201 - 83s - loss: 0.6931 - accuracy: 0.5640 - val_loss: 0.6931 - val_accuracy: 0.5540\n",
      "Epoch 00003: early stopping\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 0.6931 - accuracy: 0.5540\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Glasses_and_Sunglasses\\Run-02\\assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size': 5, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "201/201 - 92s - loss: 0.7111 - accuracy: 0.5280 - val_loss: 0.6931 - val_accuracy: 0.5320\n",
      "Epoch 2/15\n",
      "201/201 - 97s - loss: 0.6931 - accuracy: 0.5495 - val_loss: 0.6931 - val_accuracy: 0.5960\n",
      "Epoch 3/15\n",
      "201/201 - 85s - loss: 0.6931 - accuracy: 0.5855 - val_loss: 0.6931 - val_accuracy: 0.6060\n",
      "Epoch 4/15\n",
      "201/201 - 91s - loss: 0.6931 - accuracy: 0.5735 - val_loss: 0.6931 - val_accuracy: 0.3860\n",
      "Epoch 00004: early stopping\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.6931 - accuracy: 0.3860\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Glasses_and_Sunglasses\\Run-03\\assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size': 5, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "201/201 - 147s - loss: 0.7170 - accuracy: 0.4210 - val_loss: 0.6931 - val_accuracy: 0.3860\n",
      "Epoch 2/15\n",
      "201/201 - 146s - loss: 0.6931 - accuracy: 0.4008 - val_loss: 0.6931 - val_accuracy: 0.3860\n",
      "Epoch 3/15\n",
      "201/201 - 144s - loss: 0.6931 - accuracy: 0.4035 - val_loss: 0.6931 - val_accuracy: 0.3860\n",
      "Epoch 4/15\n",
      "201/201 - 146s - loss: 0.6931 - accuracy: 0.5540 - val_loss: 0.6931 - val_accuracy: 0.6080\n",
      "Epoch 5/15\n",
      "201/201 - 149s - loss: 0.6931 - accuracy: 0.5942 - val_loss: 0.6931 - val_accuracy: 0.3860\n",
      "Epoch 00005: early stopping\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.6931 - accuracy: 0.3860\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model Glasses_and_Sunglasses\\Run-04\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "\n",
    "        hparams = {\n",
    "            HP_FILTER_SIZE: filter_size,\n",
    "            HP_FILTER_NUM: filter_num\n",
    "        }\n",
    "\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('Logs_Practical/Model Glasses_and_Sunglasses/hparam_tuning/' + run_name, hparams, session_num)\n",
    "\n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca5fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07633faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models\\Model Glasses_and_Sunglasses\\Run-04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1313871a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 237ms/step - loss: 0.6931 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(images_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "373bc852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6931. Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d0a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9517daae",
   "metadata": {},
   "source": [
    "## Visualizing in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66e41284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14328), started 0:01:14 ago. (Use '!kill 14328' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2072590ac201659a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2072590ac201659a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Glasses_and_Sunglasses/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6becd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a6c5d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15264), started 0:00:58 ago. (Use '!kill 15264' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-45472dac3368c0cf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-45472dac3368c0cf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs_Practical/Model Glasses_and_Sunglasses/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630361a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
